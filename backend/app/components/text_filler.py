"""
Text FillerèŠ‚ç‚¹ - ç²¾ç¡®åŸæ–‡å¡«å……ï¼ˆåŸºäºMinerU content_listï¼‰

ä½¿ç”¨MinerUè§£æçš„content_listä¸ºæ¯ä¸ªèŠ‚ç‚¹å¡«å……ç²¾ç¡®çš„åŸæ–‡å†…å®¹
æ”¯æŒæ–‡æœ¬ã€åˆ—è¡¨ã€å›¾ç‰‡ã€è¡¨æ ¼ç­‰å¤šç§ç±»å‹çš„å†…å®¹
"""

from typing import Dict, Any, List, Optional, Tuple
from loguru import logger
from app.domain.schema import DocumentAnalysisState, PageIndexNode, PageIndexDocument
from app.tools.section_slicer import (
    extract_content_by_title_range,
    extract_bbox_positions_with_titles,
    extract_content_between,
    extract_text_by_page_range,
)
from app.services.llm_client import get_llm_client
from app.services.task_tracker import TaskTracker
from app.domain.settings import settings
from app.tools.progress_helper import log_step


def text_filler_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Text FillerèŠ‚ç‚¹ - ä¸ºå•ä¸ªèŠ‚ç‚¹å¡«å……ç²¾ç¡®åŸæ–‡ï¼ˆåŸºäºMinerUï¼Œå¹¶è¡Œç‰ˆæœ¬ï¼‰
    
    è¾“å…¥ï¼š
    - state["node"]: å•ä¸ªPageIndexNode
    - state["pageindex_document"]: å®Œæ•´æ–‡æ¡£ï¼ˆç”¨äºæŸ¥æ‰¾å…„å¼ŸèŠ‚ç‚¹ï¼‰
    - state["mineru_content_list"]: MinerUè§£æçš„å†…å®¹åˆ—è¡¨
    - state["mineru_output_dir"]: MinerUè¾“å‡ºç›®å½•
    
    è¾“å‡ºï¼š
    - æ›´æ–°nodeçš„original_textå’Œsummaryå­—æ®µ
    
    å·¥ä½œæµç¨‹ï¼š
    1. è®¡ç®—èŠ‚ç‚¹çš„é¡µé¢èŒƒå›´ï¼ˆéœ€è¦å…„å¼ŸèŠ‚ç‚¹ä¿¡æ¯ï¼‰
    2. ä½¿ç”¨title_matcherä»content_listä¸­æå–å†…å®¹
    3. å¡«å……åˆ°èŠ‚ç‚¹çš„original_textå­—æ®µï¼ˆåŒ…å«å›¾ç‰‡ã€è¡¨æ ¼çš„Markdownæ ¼å¼ï¼‰
    4. ç”Ÿæˆsummary
    """
    node = state.get("node")
    pageindex_doc = state.get("pageindex_document")
    mineru_content_list = state.get("mineru_content_list")
    mineru_output_dir = state.get("mineru_output_dir")
    task_id = state.get("task_id")
    
    if not node:
        logger.error("æœªæ‰¾åˆ°nodeï¼Œæ— æ³•å¡«å……åŸæ–‡")
        return {}
    
    if not mineru_content_list:
        logger.error("æœªæ‰¾åˆ°mineru_content_listï¼Œæ— æ³•æå–å†…å®¹")
        logger.warning("è¯·ç¡®ä¿MinerUè§£æèŠ‚ç‚¹å·²æˆåŠŸæ‰§è¡Œ")
        return {}
    
    try:
        # æ‰¾åˆ°è¯¥èŠ‚ç‚¹çš„å…„å¼ŸèŠ‚ç‚¹åˆ—è¡¨
        siblings = find_siblings(node, pageindex_doc)
        
        # å¡«å……å•ä¸ªèŠ‚ç‚¹çš„åŸæ–‡ï¼ˆç›´æ¥ä¿®æ”¹èŠ‚ç‚¹å¯¹è±¡ï¼Œæ— éœ€è¿”å›ï¼‰
        fill_single_node_text(
            node=node,
            pageindex_document=pageindex_doc,
            mineru_content_list=mineru_content_list,
            mineru_output_dir=mineru_output_dir,
            siblings=siblings,
            task_id=task_id
        )
        
        # ä¸è¿”å›ä»»ä½•ä¸œè¥¿ï¼èŠ‚ç‚¹å·²é€šè¿‡å¼•ç”¨ä¼ é€’è¢«ä¿®æ”¹
        return {}
        
    except Exception as e:
        logger.error(f"å¡«å……èŠ‚ç‚¹ '{node.title}' çš„åŸæ–‡æ—¶å‡ºé”™: {e}")
        logger.exception(e)
        # å‡ºé”™æ—¶ç¡®ä¿å­—æ®µå®Œæ•´æ€§
        node.original_text = ""
        node.summary = ""
        return {}


def find_siblings(node: PageIndexNode, pageindex_doc: PageIndexDocument) -> List[PageIndexNode]:
    """
    åœ¨æ–‡æ¡£æ ‘ä¸­æ‰¾åˆ°èŠ‚ç‚¹çš„å…„å¼ŸèŠ‚ç‚¹åˆ—è¡¨
    
    Args:
        node: ç›®æ ‡èŠ‚ç‚¹
        pageindex_doc: å®Œæ•´æ–‡æ¡£
        
    Returns:
        åŒ…å«è¯¥èŠ‚ç‚¹çš„å…„å¼ŸèŠ‚ç‚¹åˆ—è¡¨ï¼ˆåŒ…æ‹¬èŠ‚ç‚¹è‡ªå·±ï¼‰
    """
    def find_in_tree(current_list: List[PageIndexNode]) -> Optional[List[PageIndexNode]]:
        """é€’å½’æŸ¥æ‰¾èŠ‚ç‚¹æ‰€åœ¨çš„å…„å¼Ÿåˆ—è¡¨"""
        for n in current_list:
            if n is node:
                return current_list
            if n.nodes:
                result = find_in_tree(n.nodes)
                if result is not None:
                    return result
        return None
    
    # ä»æ ¹èŠ‚ç‚¹å¼€å§‹æŸ¥æ‰¾
    siblings = find_in_tree(pageindex_doc.structure)
    if siblings is None:
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå¯èƒ½æ˜¯æ ¹èŠ‚ç‚¹
        siblings = pageindex_doc.structure
    
    return siblings


def fill_single_node_text(
    node: PageIndexNode,
    pageindex_document: PageIndexDocument,
    mineru_content_list: List[Dict[str, Any]],
    mineru_output_dir: str,
    siblings: List[PageIndexNode],
    task_id: Optional[str] = None
):
    """
    å¡«å……å•ä¸ªèŠ‚ç‚¹çš„åŸæ–‡ï¼ˆåŸºäºMinerU content_listï¼‰
    
    Args:
        node: å½“å‰èŠ‚ç‚¹
        pageindex_document: å®Œæ•´æ–‡æ¡£ï¼ˆç”¨äºæŸ¥æ‰¾çˆ¶èŠ‚ç‚¹çš„å…„å¼Ÿï¼‰
        mineru_content_list: MinerUè§£æçš„å†…å®¹åˆ—è¡¨
        mineru_output_dir: MinerUè¾“å‡ºç›®å½•
        siblings: å…„å¼ŸèŠ‚ç‚¹åˆ—è¡¨ï¼ˆåŒ…å«è‡ªå·±ï¼‰
        task_id: ä»»åŠ¡ID
    """
    try:
        # 1. ç¡®å®šç»“æŸè¾¹ç•Œæ ‡é¢˜ï¼ˆç°åœ¨titleå·²åŒ…å«å®Œæ•´åºå·ï¼‰
        end_boundary_title = None
        if node.nodes:
            # æœ‰å­èŠ‚ç‚¹ï¼šè¾¹ç•Œæ˜¯ç¬¬ä¸€ä¸ªå­èŠ‚ç‚¹
            end_boundary_title = node.nodes[0].title
        else:
            # å¶å­èŠ‚ç‚¹ï¼šå…ˆæ‰¾ç›´æ¥å…„å¼Ÿ
            next_sibling = node.find_next_sibling(siblings) if siblings else None
            if next_sibling:
                end_boundary_title = next_sibling.title
            else:
                # æ²¡æœ‰ç›´æ¥å…„å¼Ÿï¼šå‘ä¸ŠæŸ¥æ‰¾çˆ¶èŠ‚ç‚¹çš„å…„å¼Ÿ
                end_boundary_title = _find_parent_sibling_title(node, pageindex_document)
        
        # 2. è®¡ç®—å½“å‰èŠ‚ç‚¹çš„é¡µé¢èŒƒå›´
        start_page, end_page = calculate_text_fill_range(node, siblings)
        
        # åˆ¤æ–­èŠ‚ç‚¹ç±»å‹ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        node_type = "æœ‰å­èŠ‚ç‚¹" if node.nodes else "å¶å­èŠ‚ç‚¹"
        boundary_info = f"è¾¹ç•Œ='{end_boundary_title}'" if end_boundary_title else "è¾¹ç•Œ=èŠ‚ç‚¹ç»“æŸé¡µ"
        
        logger.info(
            f"ğŸ“„ èŠ‚ç‚¹ '{node.title}' (ID: {node.node_id})\n"
            f"   ç±»å‹: {node_type}\n"
            f"   é¡µé¢èŒƒå›´ï¼ˆPageIndex, 1-basedï¼‰: [{start_page}, {end_page}]\n"
            f"   {boundary_info}"
        )
        
        # 2. åŠ¨æ€æ‰©å±•é¡µé¢èŒƒå›´
        boundary_page_idx = None
        if end_boundary_title:
            # å°è¯•åœ¨content_listä¸­æŸ¥æ‰¾è¾¹ç•Œæ ‡é¢˜
            boundary_page_idx = _find_title_page_idx(end_boundary_title, mineru_content_list)
        
        if boundary_page_idx is not None:
            # æƒ…å†µAï¼šè¾¹ç•Œæ ‡é¢˜å­˜åœ¨äºcontent_list - æ‰©å±•åˆ°åŒ…å«è¾¹ç•Œæ ‡é¢˜é¡µ
            boundary_page_1based = boundary_page_idx + 1
            if boundary_page_1based > end_page:
                logger.debug(
                    f"   ğŸ“ æ‰©å±•é¡µé¢èŒƒå›´ä»¥åŒ…å«è¾¹ç•Œæ ‡é¢˜:\n"
                    f"      è¾¹ç•Œæ ‡é¢˜: '{end_boundary_title}'\n"
                    f"      åŸèŒƒå›´: [{start_page}, {end_page}]\n"
                    f"      æ–°èŒƒå›´: [{start_page}, {boundary_page_1based}]"
                )
                end_page = boundary_page_1based
        else:
            # æƒ…å†µBï¼šæ— è¾¹ç•Œæ ‡é¢˜ æˆ– è¾¹ç•Œæ ‡é¢˜åœ¨content_listä¸­æ‰¾ä¸åˆ°
            # â†’ æ‰©å±•åˆ°æ–‡æ¡£çœŸå®ç»“å°¾
            doc_last_page = _get_document_last_page(mineru_content_list)
            if doc_last_page is not None:
                doc_last_page_1based = doc_last_page + 1
                if doc_last_page_1based > end_page:
                    if end_boundary_title:
                        logger.debug(
                            f"   âš ï¸  è¾¹ç•Œæ ‡é¢˜åœ¨content_listä¸­æœªæ‰¾åˆ°ï¼Œæ‰©å±•åˆ°æ–‡æ¡£ç»“å°¾:\n"
                            f"      è¾¹ç•Œæ ‡é¢˜: '{end_boundary_title}'\n"
                            f"      åŸèŒƒå›´: [{start_page}, {end_page}]\n"
                            f"      æ–‡æ¡£å®é™…ç»“å°¾: ç¬¬{doc_last_page_1based}é¡µ\n"
                            f"      æ–°èŒƒå›´: [{start_page}, {doc_last_page_1based}]"
                        )
                    else:
                        logger.debug(
                            f"   ğŸ“„ æ‰©å±•åˆ°æ–‡æ¡£ç»“å°¾:\n"
                            f"      è¿™æ˜¯æ–‡æ¡£æœ€åèŠ‚ç‚¹\n"
                            f"      åŸèŒƒå›´: [{start_page}, {end_page}]\n"
                            f"      æ–‡æ¡£å®é™…ç»“å°¾: ç¬¬{doc_last_page_1based}é¡µ\n"
                            f"      æ–°èŒƒå›´: [{start_page}, {doc_last_page_1based}]"
                        )
                    end_page = doc_last_page_1based
        
        # 3. å¦‚æœé¡µé¢èŒƒå›´æœ‰æ•ˆï¼Œä½¿ç”¨title_matcheræå–å†…å®¹
        if start_page <= end_page and end_page > 0:
            # ã€å…³é”®è½¬æ¢ã€‘PageIndexæ˜¯1-basedï¼ŒMinerUæ˜¯0-based
            # PageIndexçš„start_index=3è¡¨ç¤ºPDFç¬¬3é¡µ
            # MinerUçš„page_idx=2è¡¨ç¤ºPDFç¬¬3é¡µ
            mineru_start_page = start_page - 1
            mineru_end_page = end_page - 1
            
            logger.info(
                f"   âœ“ ç´¢å¼•è½¬æ¢å®Œæˆ:\n"
                f"     PageIndex (1-based): [{start_page}, {end_page}]\n"
                f"     MinerU (0-based):    [{mineru_start_page}, {mineru_end_page}]\n"
                f"     å¯¹åº”PDFé¡µç : ç¬¬{start_page}é¡µåˆ°ç¬¬{end_page}é¡µ"
            )
            
            # ä½¿ç”¨é²æ£’çš„å¤šç­–ç•¥æ ‡é¢˜åŒ¹é…ï¼ˆçº§è” fallbackï¼‰
            from app.tools.section_slicer import TitleMatcher, extract_bbox_positions
            
            # 1. ä½¿ç”¨é²æ£’æ–¹æ³•æ‰¾åˆ°èµ·å§‹æ ‡é¢˜çš„ç´¢å¼•ï¼ˆ5 çº§ç­–ç•¥çº§è”ï¼‰
            start_idx = TitleMatcher.find_title_in_content_list_robust(
                node.title,
                mineru_content_list,
                (mineru_start_page, mineru_end_page)
            )
            
            if start_idx is not None:
                # 2. ç¡®å®šæœ‰æ•ˆé¡µé¢èŒƒå›´ï¼ˆå¦‚æœæ ‡é¢˜åœ¨æ‰©å±•èŒƒå›´ä¸­æ‰¾åˆ°ï¼Œéœ€æ‰©å¤§åˆ‡ç‰‡èŒƒå›´ï¼‰
                found_page = mineru_content_list[start_idx].get("page_idx", mineru_start_page)
                effective_start = min(mineru_start_page, found_page)
                effective_end = max(mineru_end_page, found_page + 3)
                
                # 3. åŸºäºå·²çŸ¥ start_idx ç›´æ¥æå–å†…å®¹ï¼ˆé¿å…é‡å¤æœç´¢èµ·å§‹æ ‡é¢˜ï¼‰
                contents = extract_content_between(
                    start_idx=start_idx,
                    end_title=end_boundary_title,
                    content_list=mineru_content_list,
                    page_range=(effective_start, effective_end)
                )
                original_text = TitleMatcher.extract_text_from_contents(contents)
                
                # 4. æå– positionsï¼ˆåŒ…å«èµ·å§‹æ ‡é¢˜çš„ bboxï¼‰
                start_content = mineru_content_list[start_idx]
                contents_with_title = [start_content] + contents
                positions = extract_bbox_positions(contents_with_title)
            else:
                # æ‰€æœ‰æ ‡é¢˜åŒ¹é…ç­–ç•¥å‡å¤±è´¥ â†’ é¡µé¢èŒƒå›´å…œåº•æå–
                logger.warning(
                    f"èŠ‚ç‚¹ '{node.title}' çš„æ ‡é¢˜åœ¨content_listä¸­æœªæ‰¾åˆ°"
                    f"ï¼ˆ5çº§é²æ£’ç­–ç•¥å‡å¤±è´¥ï¼‰ï¼Œä½¿ç”¨é¡µé¢èŒƒå›´æ–‡æœ¬æå–ä½œä¸ºfallback"
                )
                fallback_text, fallback_contents = extract_text_by_page_range(
                    mineru_content_list, mineru_start_page, mineru_end_page
                )
                original_text = fallback_text
                positions = extract_bbox_positions(fallback_contents)
            
            # å¡«å……åˆ°èŠ‚ç‚¹
            node.original_text = original_text if original_text else ""
            node.positions = positions if positions else []
            
            # è®°å½•å¡«å……çŠ¶æ€
            if original_text and len(original_text.strip()) > 0:
                logger.debug(f"   âœ… åŸæ–‡æå–æˆåŠŸ: é•¿åº¦={len(original_text)}")
                logger.debug(f"   ğŸ“ åæ ‡æå–æˆåŠŸ: {len(positions)} ä¸ªbbox")
                
                # ç»Ÿè®¡å†…å®¹ç±»å‹ï¼ˆæ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡/è¡¨æ ¼ï¼‰
                has_images = "![" in original_text
                if has_images:
                    image_count = original_text.count("![")
                    logger.debug(f"   ğŸ“· åŒ…å« {image_count} ä¸ªå›¾ç‰‡/è¡¨æ ¼ï¼ˆMarkdownæ ¼å¼ï¼‰")
                
                # ç”Ÿæˆsummary
                summary = generate_summary_from_text(
                    node_title=node.title,
                    original_text=original_text
                )
                node.summary = summary
                logger.debug(f"   ğŸ“ Summaryå·²ç”Ÿæˆï¼Œé•¿åº¦: {len(summary)}")
            else:
                # å³ä½¿æ²¡æœ‰æ­£æ–‡å†…å®¹ï¼Œä¹Ÿè¦ä¿ç•™æ ‡é¢˜çš„bboxåæ ‡
                logger.debug(
                    f"   â„¹ï¸  èŠ‚ç‚¹æ— æ­£æ–‡å†…å®¹: original_textå·²è®¾ä¸ºç©ºå­—ç¬¦ä¸²\n"
                    f"   èŠ‚ç‚¹: {node.title} (ID: {node.node_id})\n"
                    f"   ğŸ“ ä½†ä¿ç•™äº†æ ‡é¢˜bbox: {len(positions)} ä¸ªåæ ‡\n"
                    f"   å¯èƒ½åŸå› : 1) æ ‡é¢˜ä¸‹ç¡®å®æ— å†…å®¹ 2) å†…å®¹åœ¨å­èŠ‚ç‚¹ä¸­"
                )
                node.summary = ""
                # ä¸è¦æ¸…ç©ºpositionsï¼ä¿ç•™æ ‡é¢˜çš„bbox
            
            logger.debug(f"   âœ… åŸæ–‡å¡«å……å®Œæˆ\n")
        else:
            logger.warning(
                f"èŠ‚ç‚¹ '{node.title}' çš„é¡µé¢èŒƒå›´æ— æ•ˆ: "
                f"[{start_page}, {end_page}]"
            )
            node.original_text = ""
            node.summary = ""
            node.positions = []
        
    except Exception as e:
        logger.error(f"å¡«å……èŠ‚ç‚¹ '{node.title}' çš„åŸæ–‡æ—¶å‡ºé”™: {e}")
        logger.exception(e)
        node.original_text = ""
        node.summary = ""
        node.positions = []


def calculate_text_fill_range(
    node: PageIndexNode,
    siblings: Optional[List[PageIndexNode]] = None
) -> Tuple[int, int]:
    """
    è®¡ç®—èŠ‚ç‚¹åº”è¯¥å¡«å……çš„æ–‡æœ¬æ‰€å¯¹åº”çš„PDFé¡µé¢èŒƒå›´
    
    è§„åˆ™ï¼ˆä¿®æ­£ï¼‰ï¼š
    1. æœ‰å­èŠ‚ç‚¹ï¼š[node.start_index, first_child.start_index]
       - æå–åˆ°åŒ…å«ç¬¬ä¸€ä¸ªå­èŠ‚ç‚¹æ ‡é¢˜çš„é¡µé¢ï¼Œè®©LLMè¯†åˆ«è¾¹ç•Œ
    2. å¶å­èŠ‚ç‚¹+æœ‰å…„å¼Ÿï¼š[node.start_index, next_sibling.start_index]
       - æå–åˆ°åŒ…å«ä¸‹ä¸€ä¸ªå…„å¼Ÿæ ‡é¢˜çš„é¡µé¢ï¼Œè®©LLMè¯†åˆ«è¾¹ç•Œ
    3. å¶å­èŠ‚ç‚¹+æ— å…„å¼Ÿï¼š[node.start_index, node.end_index]
       - æå–åˆ°èŠ‚ç‚¹çš„ç»“æŸé¡µ
    
    æ ¸å¿ƒç†å¿µï¼šå¿…é¡»åŒ…å«è¾¹ç•Œæ ‡é¢˜æ‰€åœ¨é¡µï¼Œè®©LLMåœ¨æ–‡æœ¬ä¸­è¯†åˆ«è¾¹ç•Œå¹¶åœæ­¢
    
    Args:
        node: å½“å‰èŠ‚ç‚¹
        siblings: å…„å¼ŸèŠ‚ç‚¹åˆ—è¡¨ï¼ˆåŒ…å«å½“å‰èŠ‚ç‚¹ï¼‰
        
    Returns:
        (start_page, end_page) 1-based, é—­åŒºé—´
    """
    start_page = node.start_index
    
    if node.nodes:  # æœ‰å­èŠ‚ç‚¹
        # ç»“æŸé¡µ = ç¬¬ä¸€ä¸ªå­èŠ‚ç‚¹çš„å¼€å§‹é¡µï¼ˆåŒ…å«è¾¹ç•Œæ ‡é¢˜ï¼‰
        end_page = node.nodes[0].start_index
    else:  # å¶å­èŠ‚ç‚¹
        # æ‰¾ä¸‹ä¸€ä¸ªå…„å¼Ÿ
        next_sibling = node.find_next_sibling(siblings) if siblings else None
        
        if next_sibling:
            # ç»“æŸé¡µ = ä¸‹ä¸€ä¸ªå…„å¼Ÿçš„å¼€å§‹é¡µï¼ˆåŒ…å«è¾¹ç•Œæ ‡é¢˜ï¼‰
            end_page = next_sibling.start_index
        else:
            # æ²¡æœ‰ä¸‹ä¸€ä¸ªå…„å¼Ÿï¼Œä½¿ç”¨è‡ªå·±çš„ç»“æŸé¡µ
            end_page = node.end_index
    
    # ç¡®ä¿é¡µé¢èŒƒå›´æœ‰æ•ˆ
    if end_page < start_page:
        logger.warning(
            f"èŠ‚ç‚¹ '{node.title}' è®¡ç®—çš„ç»“æŸé¡µ ({end_page}) "
            f"å°äºå¼€å§‹é¡µ ({start_page})ï¼Œå¼ºåˆ¶ä½¿ç”¨å¼€å§‹é¡µ"
        )
        end_page = start_page
    
    return (start_page, end_page)


def generate_summary_from_text(
    node_title: str,
    original_text: str,
    max_length: int = 500
) -> str:
    """
    åŸºäºç²¾ç¡®åŸæ–‡ç”Ÿæˆæ‘˜è¦
    
    Args:
        node_title: èŠ‚ç‚¹æ ‡é¢˜
        original_text: ç²¾ç¡®æå–çš„åŸæ–‡
        max_length: æ‘˜è¦æœ€å¤§é•¿åº¦
        
    Returns:
        ç”Ÿæˆçš„æ‘˜è¦
    """
    try:
        llm_service = get_llm_client()
        
        prompt = f"""è¯·ä¸ºä»¥ä¸‹ç« èŠ‚å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ˜æ‰¼è¦çš„æ‘˜è¦ã€‚

**ç« èŠ‚æ ‡é¢˜**ï¼š{node_title}

**ç« èŠ‚åŸæ–‡**ï¼š
{original_text}

**è¦æ±‚**ï¼š
1. æ‘˜è¦åº”ç®€æ´æ˜äº†ï¼Œé•¿åº¦æ§åˆ¶åœ¨{max_length}å­—ä»¥å†…
2. æç‚¼æ ¸å¿ƒè¦ç‚¹ï¼Œä¿ç•™å…³é”®ä¿¡æ¯
3. ä½¿ç”¨å®¢è§‚ã€ä¸“ä¸šçš„è¯­è¨€
4. ç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ï¼Œä¸è¦æ·»åŠ "æ‘˜è¦ï¼š"ç­‰å‰ç¼€

**è¾“å‡ºæ‘˜è¦**ï¼š"""
        
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£æ‘˜è¦ä¸“å®¶ï¼Œæ“…é•¿æç‚¼æ–‡æœ¬çš„æ ¸å¿ƒå†…å®¹ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
        
        summary = llm_service.text_completion(
            messages=messages,
            model=settings.summarizer_llm_name,  # summarizer-specific model
            temperature=0.3,
            max_tokens=1000
        )
        
        return summary.strip() if summary else ""
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆsummaryæ—¶å‡ºé”™: {e}")
        # é™çº§ï¼šä½¿ç”¨åŸæ–‡å‰500å­—ä½œä¸ºæ‘˜è¦
        return original_text[:500] + "..." if len(original_text) > 500 else original_text


def _find_title_page_idx(
    target_title: str,
    content_list: List[Dict[str, Any]]
) -> Optional[int]:
    """
    åœ¨content_listä¸­æŸ¥æ‰¾æ ‡é¢˜æ‰€åœ¨çš„é¡µç ï¼ˆpage_idxï¼Œ0-basedï¼‰
    
    Args:
        target_title: ç›®æ ‡æ ‡é¢˜
        content_list: MinerUè§£æçš„å†…å®¹åˆ—è¡¨
        
    Returns:
        æ‰¾åˆ°çš„page_idxï¼ˆ0-basedï¼‰ï¼Œæœªæ‰¾åˆ°è¿”å›None
    """
    from app.tools.section_slicer import TitleMatcher
    
    # ä½¿ç”¨é²æ£’æ–¹æ³•æŸ¥æ‰¾æ ‡é¢˜ï¼ˆæ— é¡µé¢èŒƒå›´é™åˆ¶æ—¶æœ¬è´¨ä¸Šåªæœ‰ç­–ç•¥1ç”Ÿæ•ˆï¼Œ
    # ä½†ä¿æŒä¸€è‡´æ€§ï¼Œä¸” light normalization ç­–ç•¥ä»å¯æä¾›é¢å¤–åŒ¹é…èƒ½åŠ›ï¼‰
    title_idx = TitleMatcher.find_title_in_content_list_robust(
        target_title,
        content_list,
        page_range=None  # ä¸é™åˆ¶é¡µé¢èŒƒå›´
    )
    
    if title_idx is not None:
        # è¿”å›è¯¥contentçš„page_idx
        return content_list[title_idx].get("page_idx")
    return None


def _find_parent_sibling_title(
    node: PageIndexNode,
    pageindex_document: PageIndexDocument
) -> Optional[str]:
    """
    é€’å½’å‘ä¸ŠæŸ¥æ‰¾çˆ¶/ç¥–å…ˆèŠ‚ç‚¹çš„ä¸‹ä¸€ä¸ªå…„å¼Ÿä½œä¸ºè¾¹ç•Œæ ‡é¢˜
    
    æŸ¥æ‰¾ç­–ç•¥ï¼š
    1. æŸ¥æ‰¾çˆ¶èŠ‚ç‚¹çš„ä¸‹ä¸€ä¸ªå…„å¼Ÿ
    2. å¦‚æœçˆ¶èŠ‚ç‚¹æ²¡æœ‰å…„å¼Ÿï¼Œç»§ç»­å‘ä¸ŠæŸ¥æ‰¾ç¥–çˆ¶èŠ‚ç‚¹çš„å…„å¼Ÿ
    3. é€’å½’å‘ä¸Šï¼Œç›´åˆ°æ‰¾åˆ°æˆ–åˆ°è¾¾æ ¹èŠ‚ç‚¹
    4. å¦‚æœåˆ°æ ¹èŠ‚ç‚¹è¿˜æ²¡æ‰¾åˆ°ï¼Œè¿”å›Noneï¼ˆè¡¨ç¤ºæ˜¯æ–‡æ¡£çš„æœ€åèŠ‚ç‚¹ï¼‰
    
    Args:
        node: å½“å‰èŠ‚ç‚¹
        pageindex_document: å®Œæ•´æ–‡æ¡£
        
    Returns:
        æ‰¾åˆ°çš„ç¥–å…ˆå…„å¼Ÿæ ‡é¢˜ï¼Œæœªæ‰¾åˆ°è¿”å›Noneï¼ˆè¡¨ç¤ºåˆ°æ–‡æ¡£ç»“å°¾ï¼‰
    """
    def find_node_path(
        target: PageIndexNode,
        current_list: List[PageIndexNode],
        path: List[Tuple[PageIndexNode, List[PageIndexNode]]]
    ) -> Optional[List[Tuple[PageIndexNode, List[PageIndexNode]]]]:
        """
        é€’å½’æŸ¥æ‰¾èŠ‚ç‚¹çš„å®Œæ•´è·¯å¾„
        
        Returns:
            è·¯å¾„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯(èŠ‚ç‚¹, è¯¥èŠ‚ç‚¹çš„å…„å¼Ÿåˆ—è¡¨)
        """
        for i, n in enumerate(current_list):
            if n is target:
                # æ‰¾åˆ°ç›®æ ‡èŠ‚ç‚¹
                path.append((n, current_list))
                return path
            if n.nodes:
                # è®°å½•å½“å‰èŠ‚ç‚¹åŠå…¶å…„å¼Ÿåˆ—è¡¨
                new_path = path + [(n, current_list)]
                # é€’å½’æŸ¥æ‰¾å­èŠ‚ç‚¹
                result = find_node_path(target, n.nodes, new_path)
                if result:
                    return result
        return None
    
    # 1. æ‰¾åˆ°ä»æ ¹åˆ°ç›®æ ‡èŠ‚ç‚¹çš„å®Œæ•´è·¯å¾„
    path = find_node_path(node, pageindex_document.structure, [])
    
    if not path:
        return None
    
    # 2. ä»è·¯å¾„å€’åºéå†ï¼ˆä»ç›®æ ‡èŠ‚ç‚¹å‘ä¸Šåˆ°æ ¹èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ï¼‰
    # path[-1] æ˜¯ç›®æ ‡èŠ‚ç‚¹æœ¬èº«ï¼Œpath[-2]æ˜¯çˆ¶èŠ‚ç‚¹ï¼Œpath[-3]æ˜¯ç¥–çˆ¶èŠ‚ç‚¹...
    # æ³¨æ„ï¼šrangeè¦ä»len(path)-1åˆ°0ï¼ˆåŒ…å«ï¼‰ï¼Œè¿™æ ·æ‰èƒ½æ£€æŸ¥æ‰€æœ‰å±‚çº§çš„å…„å¼Ÿ
    for i in range(len(path) - 1, -1, -1):
        current_node, siblings = path[i]
        
        # åœ¨å…„å¼Ÿåˆ—è¡¨ä¸­æ‰¾åˆ°å½“å‰èŠ‚ç‚¹çš„ä¸‹ä¸€ä¸ªå…„å¼Ÿ
        try:
            current_idx = siblings.index(current_node)
            if current_idx < len(siblings) - 1:
                # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå…„å¼Ÿ
                next_sibling = siblings[current_idx + 1]
                logger.debug(
                    f"   â¬†ï¸  å‘ä¸ŠæŸ¥æ‰¾è¾¹ç•Œ:\n"
                    f"      å½“å‰èŠ‚ç‚¹: {node.title}\n"
                    f"      æŸ¥æ‰¾å±‚çº§: å‘ä¸Š{len(path) - 1 - i}å±‚\n"
                    f"      æ‰¾åˆ°è¾¹ç•Œ: {next_sibling.title}"
                )
                return next_sibling.title
        except ValueError:
            continue
    
    # 3. å¦‚æœé€’å½’åˆ°æ ¹èŠ‚ç‚¹è¿˜æ²¡æ‰¾åˆ°ï¼Œè¯´æ˜æ˜¯æ–‡æ¡£æœ€åçš„èŠ‚ç‚¹
    logger.debug(
        f"   ğŸ“„ èŠ‚ç‚¹ '{node.title}' æ˜¯æ–‡æ¡£çš„æœ€åèŠ‚ç‚¹\n"
        f"      å°†æå–åˆ°æ–‡æ¡£ç»“å°¾"
    )
    return None


def _get_document_last_page(content_list: List[Dict[str, Any]]) -> Optional[int]:
    """
    è·å–æ–‡æ¡£çš„æœ€åä¸€é¡µé¡µç ï¼ˆpage_idxï¼Œ0-basedï¼‰
    
    Args:
        content_list: MinerUè§£æçš„å†…å®¹åˆ—è¡¨
        
    Returns:
        æœ€åä¸€é¡µçš„page_idxï¼ˆ0-basedï¼‰ï¼Œæœªæ‰¾åˆ°è¿”å›None
    """
    if not content_list:
        return None
    
    # æ‰¾åˆ°content_listä¸­æœ€å¤§çš„page_idx
    max_page_idx = -1
    for content in content_list:
        page_idx = content.get("page_idx", -1)
        if page_idx > max_page_idx:
            max_page_idx = page_idx
    
    return max_page_idx if max_page_idx >= 0 else None



