"""
S3-compatible object storage service (backed by MinIO).

Provides upload, download, presigned-URL generation, and deletion of
PDF files organised by task ID.
"""

import urllib.parse
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional

from loguru import logger
from minio import Minio
from minio.error import S3Error

from app.domain.settings import settings


class ObjectStorageService:
    """S3-compatible object storage wrapper (MinIO backend)."""

    _NGINX_PROXY_PREFIX = "/tender-minio"
    """Nginx reverse-proxy path prefix for presigned URLs."""

    def __init__(self) -> None:
        """Initialise the MinIO client and ensure the bucket exists."""
        try:
            self.client = Minio(
                endpoint=settings.minio_endpoint,
                access_key=settings.minio_access_key,
                secret_key=settings.minio_secret_key,
                secure=settings.minio_secure,
            )
            self.bucket_name = settings.minio_bucket

            self._ensure_bucket_exists()

            logger.info(
                f"Object storage ready: {settings.minio_endpoint}/{self.bucket_name}"
            )
        except Exception as e:
            logger.error(f"Failed to initialise object storage: {e}")
            logger.error(
                "Check configuration:\n"
                "  1. MINIO_ENDPOINT should point to the S3 API port (usually 9000), "
                "not the web-console port (usually 9001).\n"
                f"  2. Current endpoint: {settings.minio_endpoint}\n"
                "  3. Try changing the port from 19001 to 19000, or ask the MinIO "
                "administrator for the correct API port."
            )
            raise

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------

    def _ensure_bucket_exists(self) -> None:
        """Create the bucket if it does not already exist."""
        try:
            if not self.client.bucket_exists(self.bucket_name):
                self.client.make_bucket(self.bucket_name)
                logger.info(f"Created bucket: {self.bucket_name}")
            else:
                logger.debug(f"Bucket already exists: {self.bucket_name}")
        except S3Error as e:
            logger.error(f"Failed to verify/create bucket: {e}")
            raise

    def _convert_to_nginx_url(self, minio_url: str) -> str:
        """
        Rewrite a MinIO presigned URL into an Nginx-proxied path.

        Args:
            minio_url: Presigned URL generated by MinIO.

        Returns:
            URL path accessible via the Nginx reverse proxy.
        """
        parsed = urllib.parse.urlparse(minio_url)
        path = parsed.path.lstrip("/")
        nginx_path = f"{self._NGINX_PROXY_PREFIX}/{path}"
        if parsed.query:
            nginx_path = f"{nginx_path}?{parsed.query}"
        return nginx_path

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    def upload_pdf(self, file_path: str, task_id: str) -> str:
        """
        Upload a local PDF file to object storage.

        Args:
            file_path: Absolute path to the local PDF file.
            task_id: Task identifier (used to namespace the object).

        Returns:
            Direct HTTP URL of the uploaded object.
        """
        try:
            file_name = Path(file_path).name
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            object_name = f"{task_id}/{Path(file_name).stem}_{timestamp}.pdf"

            self.client.fput_object(
                bucket_name=self.bucket_name,
                object_name=object_name,
                file_path=file_path,
                content_type="application/pdf",
            )

            url = f"http://{settings.minio_endpoint}/{self.bucket_name}/{object_name}"
            logger.info(f"Uploaded PDF to object storage: {url}")
            return url

        except S3Error as e:
            logger.error(f"S3 error while uploading PDF: {e}")
            raise Exception(f"Object storage upload failed: {e}") from e
        except Exception as e:
            logger.error(f"Unexpected error while uploading PDF: {e}")
            raise

    def get_pdf_url(
        self, task_id: str, expires_hours: int = 24,
    ) -> tuple[Optional[str], Optional[str]]:
        """
        Generate presigned URLs for the first PDF under *task_id*.

        Args:
            task_id: Task identifier.
            expires_hours: URL validity period in hours (default 24).

        Returns:
            ``(direct_url, nginx_proxy_url)`` or ``(None, None)`` if
            no PDF is found.
        """
        try:
            objects = self.client.list_objects(
                bucket_name=self.bucket_name,
                prefix=f"{task_id}/",
                recursive=True,
            )

            for obj in objects:
                if obj.object_name.endswith(".pdf"):
                    direct_url = self.client.presigned_get_object(
                        bucket_name=self.bucket_name,
                        object_name=obj.object_name,
                        expires=timedelta(hours=expires_hours),
                    )
                    nginx_url = self._convert_to_nginx_url(direct_url)

                    logger.debug(f"Presigned URL (direct): {direct_url[:100]}...")
                    logger.debug(f"Presigned URL (proxy):  {nginx_url[:100]}...")

                    return direct_url, nginx_url

            logger.warning(f"No PDF found for task_id={task_id}")
            return None, None

        except S3Error as e:
            logger.error(f"S3 error while fetching PDF URL: {e}")
            return None, None
        except Exception as e:
            logger.error(f"Unexpected error while fetching PDF URL: {e}")
            return None, None

    def download_pdf(self, object_name: str, local_path: str) -> None:
        """
        Download a PDF from object storage to a local path.

        Args:
            object_name: Object key in the bucket.
            local_path: Destination path on disk.
        """
        try:
            self.client.fget_object(
                bucket_name=self.bucket_name,
                object_name=object_name,
                file_path=local_path,
            )
            logger.info(f"Downloaded PDF to {local_path}")
        except S3Error as e:
            logger.error(f"S3 error while downloading PDF: {e}")
            raise Exception(f"Object storage download failed: {e}") from e

    def delete_pdf(self, task_id: str) -> bool:
        """
        Delete all objects under *task_id*.

        Args:
            task_id: Task identifier.

        Returns:
            ``True`` on success, ``False`` on error.
        """
        try:
            objects = self.client.list_objects(
                bucket_name=self.bucket_name,
                prefix=f"{task_id}/",
                recursive=True,
            )

            deleted_count = 0
            for obj in objects:
                self.client.remove_object(
                    bucket_name=self.bucket_name,
                    object_name=obj.object_name,
                )
                logger.debug(f"Deleted object: {obj.object_name}")
                deleted_count += 1

            if deleted_count > 0:
                logger.info(
                    f"Deleted {deleted_count} object(s) for task_id={task_id}"
                )
            else:
                logger.warning(f"No objects found for task_id={task_id}")

            return True

        except (S3Error, Exception) as e:
            logger.error(f"Failed to delete objects for task_id={task_id}: {e}")
            return False


# ---------------------------------------------------------------------------
# Singleton
# ---------------------------------------------------------------------------

_storage_instance: Optional[ObjectStorageService] = None


def get_object_storage_service() -> ObjectStorageService:
    """Return the module-level ``ObjectStorageService`` singleton."""
    global _storage_instance
    if _storage_instance is None:
        _storage_instance = ObjectStorageService()
    return _storage_instance


# Backward-compatible alias
get_minio_service = get_object_storage_service
